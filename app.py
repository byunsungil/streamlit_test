# streamlit_car_news_app.py

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import requests
from bs4 import BeautifulSoup
from collections import Counter
from wordcloud import WordCloud
import re
from datetime import datetime, timedelta
import matplotlib.font_manager as fm
import plotly.express as px
import os

# ---------------------- ì„¤ì • ----------------------
st.set_page_config(page_title="ë²•ì¸ì°¨ëŸ‰ ê´€ë ¨ FAQ ì‹œìŠ¤í…œ", layout="wide")

# ---------------------- ë°ì´í„° ë¡œë“œ ----------------------
@st.cache_data
def load_car_data():
    cars = pd.read_csv("ìë™ì°¨ë“±ë¡í˜„í™©ë³´ê³ _ìë™ì°¨ë“±ë¡ëŒ€ìˆ˜í˜„í™© ì‹œë„ë³„ (201101 ~ 202502).csv", encoding="cp949", skiprows=5)
    cars.columns = ['ì¼ì‹œ', 'ì‹œë„ëª…', 'ì‹œêµ°êµ¬', 'ìŠ¹ìš©_ê´€ìš©', 'ìŠ¹ìš©_ìê°€ìš©', 'ìŠ¹ìš©_ì˜ì—…ìš©', 'ìŠ¹ìš©_ê³„',
                    'ìŠ¹í•©_ê´€ìš©', 'ìŠ¹í•©_ìê°€ìš©', 'ìŠ¹í•©_ì˜ì—…ìš©', 'ìŠ¹í•©_ê³„',
                    'í™”ë¬¼_ê´€ìš©', 'í™”ë¬¼_ìê°€ìš©', 'í™”ë¬¼_ì˜ì—…ìš©', 'í™”ë¬¼_ê³„',
                    'íŠ¹ìˆ˜_ê´€ìš©', 'íŠ¹ìˆ˜_ìê°€ìš©', 'íŠ¹ìˆ˜_ì˜ì—…ìš©', 'íŠ¹ìˆ˜_ê³„',
                    'ì´ê³„_ê´€ìš©', 'ì´ê³„_ìê°€ìš©', 'ì´ê³„_ì˜ì—…ìš©', 'ì´ê³„']
    cars = cars[(cars['ì‹œë„ëª…'] == 'ì„œìš¸') & (cars['ì‹œêµ°êµ¬'] == 'ê°•ë‚¨êµ¬')]
    cars['ì¼ì‹œ'] = pd.to_datetime(cars['ì¼ì‹œ'])
    cars['ìŠ¹ìš©_ì˜ì—…ìš©'] = cars['ìŠ¹ìš©_ì˜ì—…ìš©'].str.replace(',', '').astype(int)
    return cars[['ì¼ì‹œ', 'ìŠ¹ìš©_ì˜ì—…ìš©']]

# ---------------------- ì°¨ëŸ‰ ë¶„ì„ ----------------------
def car_analysis():
    st.title("ğŸš— ê°•ë‚¨êµ¬ ì˜ì—… ì°¨ëŸ‰ ë“±ë¡ í†µê³„")

    df = load_car_data()
    df_recent = df[-24:].reset_index(drop=True)

    avg_2023 = df_recent[:12]['ìŠ¹ìš©_ì˜ì—…ìš©'].mean()
    avg_2024 = df_recent[12:]['ìŠ¹ìš©_ì˜ì—…ìš©'].mean()

    st.write("2023-2024 ì˜ì—…ìš© ìŠ¹ìš©ì°¨ ë³€ë™ ì¶”ì´")
    fig = px.scatter(df_recent, x="ì¼ì‹œ", y="ìŠ¹ìš©_ì˜ì—…ìš©", title="ì›”ë³„ ë“±ë¡ìˆ˜ ë³€í™”")
  

    st.plotly_chart(fig)

    col1, col2, col3 = st.columns(3)

    col1.metric("ğŸš— 2023 í‰ê·  ë“±ë¡ìˆ˜", f"{avg_2023:.0f}ëŒ€")
    col2.metric("ğŸš— 2024 í‰ê·  ë“±ë¡ìˆ˜", f"{avg_2024:.0f}ëŒ€")
    diff = avg_2024 - avg_2023
    rate = (diff / avg_2023) * 100
    col3.metric("ğŸ“‰ ì „ë…„ ëŒ€ë¹„ ë³€í™”", f"{diff:+.0f}ëŒ€", f"{rate:+.1f}%")


# ---------------------- ë‰´ìŠ¤ ì›Œë“œí´ë¼ìš°ë“œ ----------------------
def news_wordcloud():
    st.title("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ì›Œë“œí´ë¼ìš°ë“œ")
    query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ìë™ì°¨ ì œë„")

    if st.button("ë¶„ì„ ì‹œì‘") and query:
        articles = []
        for page in range(1, 6):
            start = (page - 1) * 10 + 1
            url = f"https://search.naver.com/search.naver?where=news&query={query}&start={start}"
            res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
            soup = BeautifulSoup(res.text, "html.parser")
            news_items = soup.select("ul.list_news li.bx")
            for item in news_items:
                title_tag = item.select_one("a.news_tit")
                if title_tag:
                    articles.append(title_tag["title"])

        if articles:
            text = " ".join(articles)
            text = re.sub("[^ê°€-í£\s]", "", text)
            words = [w for w in text.split() if len(w) > 1]
            freq = Counter(words)

            wc = WordCloud(font_path="NanumGothicCoding.ttf", width=800, height=400, background_color="white")
            wc.generate_from_frequencies(freq)

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wc, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig)
        else:
            st.warning("ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------- ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„ ----------------------
def keyword_analysis():
    st.title("ğŸ“Š ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„")
    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(pages=10):
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={QUERY}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag: continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({ 'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link })
        return pd.DataFrame(data)

    def save_news(df_new):
        if os.path.exists(FILE_PATH):
            df_old = pd.read_csv(FILE_PATH)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
        df_all.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
        return df_all

    def keyword_visualization(df):
        font_path = './fonts/NanumGothicCoding.ttf'
        font_name = fm.FontProperties(fname=font_path).get_name() if os.path.exists(font_path) else 'Malgun Gothic'
        plt.rcParams['font.family'] = font_name
        plt.rcParams['axes.unicode_minus'] = False

        all_words = []
        for summary in df['summary'].dropna():
            words = re.findall(r"[ê°€-í£]{2,}", summary)
            all_words.extend(words)

        counter = Counter(all_words)
        common_keywords = counter.most_common(20)
        if not common_keywords:
            st.warning("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        words, counts = zip(*common_keywords)
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(x=list(counts), y=list(words), ax=ax)
        ax.set_title('ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„')
        st.pyplot(fig)

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ í˜ì´ì§€ ìˆ˜ ì…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)
    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(pages)
        df_all = save_news(df_today)
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ì¥ë¨.")
    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df_all[['date', 'title', 'press', 'summary']])

    st.subheader("í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼")
    keyword_visualization(df_all)

# ---------------------- ë‰´ìŠ¤ ìš”ì•½ -------------------------
    def truncate(text, limit=100):
        return text if len(text) <= limit else text[:limit] + "..."

    if st.toggle("ğŸ“° ë‰´ìŠ¤ ì œëª© + ë§í¬ + ìš”ì•½ ë³´ê¸°"):
        st.subheader("ğŸ“° ìš”ì•½ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")
        for i, row in df_all.iterrows():
            title = row['title']
            link = row['url']
            summary = row['summary']
            st.markdown(f"### ğŸ”— [{title}]({link})")
            st.write(f"ğŸ“ ìš”ì•½: {truncate(summary, 100)}")
            st.markdown("---")

# ---------------------- FAQ -------------------------------
def FAQ():
    st.title("ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")

# ---------------------- í˜ì´ì§€ ë¼ìš°íŒ… ----------------------
page = st.sidebar.selectbox("ë©”ë‰´ ì„ íƒ", ["ì°¨ëŸ‰ ë¶„ì„", "ë‰´ìŠ¤ ì›Œë“œí´ë¼ìš°ë“œ", "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„","ìì£¼ ë¬»ëŠ” ì§ˆë¬¸"])

if page == "ì°¨ëŸ‰ ë¶„ì„":
    car_analysis()
elif page == "ë‰´ìŠ¤ ì›Œë“œí´ë¼ìš°ë“œ":
    news_wordcloud()
elif page == "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„":
    keyword_analysis()
elif page == "ìì£¼ ë¬»ëŠ” ì§ˆë¬¸":
    FAQ()

